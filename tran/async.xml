<xml version="1.0" encoding="Latin-1"?>
<target>3</target>
<categoria>Concomitanza con processi, thread e coroutines</categoria>
<documento_tradotto>
<titolo_1>
asyncio - I/O Asincrono, ciclo di eventi e strumenti per la gestione della concorrenza
</titolo_1>
<descrizione>
Una infrastruttura per I/O asincrono e concorrenza

</descrizione>
<testo_normale>
Il modulo <strong>asyncio</strong> fornisce strumenti per costruire applicazioni concorrenti usando <em>coroutine</em>. Mentre il modulo <a href='threading.html' target='_blank'>threading</a> implementa la concorrenza attraverso <em>thread</em> di applicazione e <a href='multiprocessing.html' target='_blank'>multiprocessing</a> implementa la concorrenza usando processi di sistema, <strong>asyncio</strong> usa un approccio a <em>thread</em> singolo e processo singolo nel quale parti di un'applicazione cooperano per passarsi a compiti esplicitamente con tempistiche ottimali. Molto spesso questo contesto di scambio accade quando il programma sarebbe altrimenti bloccato in attesa di leggere o scrivere dati, m <strong>asyncio</strong> include anche il supporto per pianificare l'esecuzione di codice ad una specifico spazio temporale futuro, per abilitare una <em>coroutine</em> ad attendere che un'altra si completi, per gestire segnali di sistema e per riconoscere altri eventi che possano costituire una ragione per un'applicazione per modificare quello su cui sta lavorando.
</testo_normale>
<titolo_2>
Concetti di Concorrenza Asincrona
</titolo_2>
<testo_normale>
La maggior parte dei programmi che usano altri modelli di concorrenza sono scritti linearmente, e fanno affidamento sulla gestione del <em>thread</em> o del processo del linguaggio in fase di esecuzione o del sistema operativo per cambiare contesto quando appropriato. Una applicazione basata su <code>asyncio</code> richiede che il suo codice gestisca esplicitamente i cambi di contesto, ed usare tecniche per fare questo correttamente dipende dalla comprensione di parecchi concetti interdipendenti.
</testo_normale>
<testo_normale>
L'infrastruttura fornita da <strong>asyncio</strong> è centrata su di un <em>ciclo di eventi</em> (event loop), un oggetto di prima classe responsabile per la gestione efficiente degli eventi I/O, eventi di sistema e cambiamenti di contesto di applicazioni. Sono fornite parecchie implementazioni del ciclo per trarre vantaggio con efficienza delsyla capacità del sistema operativo. Mentre una impostazione predefinita ragionevole è di solito selezionata automaticamente, è anche possibile scegliere una implementazione particolare del ciclo di eventi all'interno dell'applicazione. Questo è utile sotto Windows, ad esempio, dove alcune classi di ciclo aggiungono supporto per processi esterni in un modo nel quale ne potrebbe beneficiare un ambiente I/O di rete.
</testo_normale>
<testo_normale>
Una applicazione interagisce con il ciclo di eventi in modo esplicito registrando il codice da eseguirsi, e lascia che il ciclo di eventi faccia le chiamate necessarie all'interno del codice dell'applicazione quando le risorse sono disponibili. Ad esempio un server di rete apre dei <em>socket</em>, quindi li registra per potere essere notificato quando su di essi si manifestano degli eventi di input. Il ciclo di eventi allerta il codice del server quando vi è una connessione in arrivo o quando ci sono dati da leggere. Ci si attende che il codice dell'applicazione riguadagni il controllo nuovamente dopo un breve periodo di tempo quando non c'è più lavoro da fare nel contesto corrente. Ad esempio se non ci sono più dati da leggere da un socket il server dovrebbe riaffidare il controllo al ciclo di eventi.
</testo_normale>
<testo_normale>
Il meccanismo per restituire il controllo al ciclo di eventi dipende dalle <em>coroutine</em> di Python, esse sono funzioni speciali per restituire il controllo al chiamante senza perdere il proprio stato. Le <em>coroutine</em> sono simili alle funzioni generatore, ad in effetti si possono usare generatori per implementare le <em>coroutine</em> in versioni di Python inferiori alla 3.5 senza il supporto nativo degli oggetti di <em>coroutine</em>. <strong>asyncio</strong> fornisce anche uno strato di astrazione basato su classi per protocolli e <em>trasporti</em> per scrivere codice usando <em>callback</em> invece di scrivere direttamente <em>coroutine</em>. In entrambi i modelli basati su classi e <em>coroutine</em> modificando esplicitamente il contesto ritornando nel ciclo di eventi equivale ad una implicita implementazione dei <em>threading</em> di Python per il cambio di contesto.
</testo_normale>
<testo_normale>
Un <em>future</em> è una struttura dati che rappresenta il risultato di un lavoro che non è ancora stato completato. Il ciclo di eventi può monitorare un oggetto <code>Future</code> per vedere quando viene impostato come ultimato, consentendo ad una parte di applicazione di attendere che un'altra parte finisca un lavoro. A parte i <em>future</em>, <strong>asyncio</strong> fornisce altri primitivi di concorrenzialità come i bloccaggi (<em>locks</em>) e i semafori.
</testo_normale>
<testo_normale>
Un <em>task</em> (compito) è una sottoclasse di <code>Future</code> che sa come impacchettare e gestire l'esecuzione per una <em>coroutine</em>. I <em>task</em> possono essere pianificati con un ciclo di eventi per essere eseguiti quando le risorse a essi necessarie sono disponibili, a per prodrurre un risultato che può essere consumato da altre <em>coroutine</em>.
</testo_normale>
<titolo_2>
Multiasking Cooperativo con Coroutine
</titolo_2>
<testo_normale>
Le <em>coroutine</em> sono un costrutto di linguaggio progettato per operazioni concorrenti. Una funzione <em>coroutine</em> crea un oggetto <em>coroutine</em> quando chiamata, poi il chiamante può eseguire il codice della funzione usando il metodo della <em>coroutine</em> <code>send()</code>. Una <em>coroutine</em> può mettere in pausa l'esecuzione usando la parola chiave <code>await</code> con un'altra <em>coroutine</em>. Mentre è il pausa, lo stato della <em>coroutine</em> viene mantenuto, in modo che possa essere ripreso dove era stato lasciato la prossima volta che viene chiamata in causa.
</testo_normale>
<titolo_3>
Fare Partire una Coroutine
</titolo_3>
<testo_normale>
Ci sono alcuni modi diversi per fare in modo che un ciclo di eventi <code>asyncio</code> faccia partire una <em>coroutine</em>. Quello più semplice è usare <code>run_until_complete()</code>, passandogli la <em>coroutine</em> direttamente.
</testo_normale>
<py_code>
# asyncio_coroutine.py
</py_code>
<testo_normale>
Il primo passo è ottenere un riferimento al ciclo di eventi. Può essere usato il tipo di ciclo predefinito, oppure può essere istanziata una classe di ciclo specifica. In questo esempio, si usa il ciclo predefinito. Il metodo <code>run_until_complete()</code> fa partire il ciclo con l'oggetto <em>coroutine</em> ed interrompe il ciclo quando la <em>coroutine</em> esce ritornando.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine.py
</py_output>
<titolo_3>
Ritornare Valori da Coroutine
</titolo_3>
<testo_normale>
Il valore di ritorno di una <em>coroutine</em> viene passato al codice che la fa partire e lo attende.
</testo_normale>
<py_code>
# asyncio_coroutine_return.py
</py_code>
<testo_normale>
In questo caso <code>run_until_complete</code> ritorna anche il risultato che la coroutine sta attendendo.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine_return.py
</py_output>
<titolo_3>
Concatenare Coroutine
</titolo_3>
<testo_normale>
Una coroutine può far partire un'altra coroutine ed attenderne il risultato. Questo facilita la suddivisione  di un compito in parti riutilizzabili. L'esempio seguente ha due fasi che devono essere eseguite in ordine, ma che possono essere eseguite concorrenzialmente con altre opearazioni
</testo_normale>
<py_code>
# asyncio_coroutine_chain.py
</py_code>
<testo_normale>
La parola chiave <code>await</code> viene usata invece che aggiungere le nuove coroutine al ciclo, poichè il flusso di controllo è già all'interno di una coroutine che è gestita da ciclo non è necessario dire al ciclo di gestire la nuova coroutine.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine_chain.py
</py_output>
<titolo_3>
Generatori Invece che Coroutine
</titolo_3>
<testo_normale>
Le funzioni coroutine sono una componente chiave della progettazione di <strong>asyncio</strong>. Esse forniscono un costrutto di linugaggio per interrompere l'esecuzione di parti di un programm, preservando lo stato di quella chiamate, e rientrando in quello stato successivamente, tutte importanti capacità per una infrastruttura di concorrenzialità.
</testo_normale>
<testo_normale>
Python 3.5 ha intradotto nuove caratteristiche di linguaggio per definire nativamente dette coroutine usando <code>async def</code> e per mantenere il controllo usando <code>await</code>. Gli esempio per <strong>asyncio</strong> traggono vantaggio dalle nuove caratteristiche. Versioni precedenti di Python 3 possono usare funzioni generatore impacchetate con il decoratore <code>asyncio.coroutine()</code> e <code>yield from</code> per ottenere lo stesso effetto.
</testo_normale>
<py_code>
# asyncio_generator.py
</py_code>
<testo_normale>
L'esempio precedente riproduce <code>asyncio_coroutine_chain.py</code> usando funzioni generatore in luogo di coroutine native.
</testo_normale>
<py_output>
$ python3 asyncio_generator.py
</py_output>
<titolo_2>
Pianificare Chiamate a Funzioni Normali
</titolo_2>
<testo_normale>
Oltre a gestire coroutine e <em>callback</em> I/O, il ciclo di eventi di <strong>asyncio</strong> può pianificare chiamate a funzioni normli in base al valore di temporizzazione conservato nel ciclo
</testo_normale>
<titolo_3>
Pianificare un Callback "Presto"
</titolo_3>
<testo_normale>
Se la tempistica del callback non importa, <code>call_soon()</code> può essere usato per pianificare la chiamata per la successiva iterazione del ciclo. Qualunque altro argomento posizionale dopo la funzione viene passato al <em>callback</em> quando viene invocato. Per passare argomenti nominali al <em>callback</em> si usi <code>partial()</code> dal modulo <a href='functools.html' target='_blank'>functools</a>.
</testo_normale>
<py_code>
# asyncio_call_soon.py
</py_code>
<testo_normale>
I <em>callback</em> sono invocati nell'ordine nel quale sono pianificati.
</testo_normale>
<py_output>
$ python3 asyncio_call_soon.py
</py_output>
<titolo_3>
Pianificare un Callback per uno Specifico Orario
</titolo_3>
<testo_normale>
E' anche possibile pianificare una chiamata ad uno specifico orario. Il ciclo usa un orologio monotonico, invece che un orologio "da muro", per assicurarsi che il valore di "adesso" non regredisca mai. Per scegliere un orario per un <em>callback</em> pianificato, è necessario partire dallo stato interno di quell'orologio usando il metodo del ciclo <code>time()</code>.
</testo_normale>
<py_code>
# asyncio_call_at.py
</py_code>
<testo_normale>
Si noti che il tempo secondo il ciclo non corrisponde al valore ritornato da <code>time.time()</code>
</testo_normale>
<py_output>
$ python3 asyncio_call_at.py
</py_output>
<titolo_2>
Produrre Risultati In Modo Asincrono
</titolo_2>
<testo_normale>
Un <code>Future</code> rappresenta il risultato di un lavoro che non è ancora stato completato. Il ciclo di eventi può osservare lo stato di un oggetto <code>Future</code> per verificare quando questo è terminato, consentendo a una parte di applicazione di attendere che un'altra finisca una qualche attività
</testo_normale>
<py_code>
# asyncio_future_event_loop.py
</py_code>
<testo_normale>
Lo stato delle modifiche di un <code>Future</code> cambia a completato quando <code>set_result()</code> viene chiamato e l'istanza di <code>Future</code> trattiene il risultato dabo al metodo per recuperarlo successivamente.
</testo_normale>
<py_output>
$ python3 asyncio_future_event_loop.py
</py_output>
<testo_normale>
Un <code>Future</code> può anche essere usato con la parola chiave <code>await</code>, come in questo esempio
</testo_normale>
<py_code>
# asyncio_future_await.py
</py_code>
<testo_normale>
Il risultato del <code>Future</code> viene ritornato da <code>await</code>, quindi è spesso possibile avere lo stesso codice che funziona sia con una <em>coroutine</em> normale che con una istanza di <code>Future</code>.
</testo_normale>
<py_output>
$ python3 asyncio_future_await.py
</py_output>
<titolo_3>
Callaback di Future
</titolo_3>
<testo_normale>
Un <code>Future</code>, oltre che lavorare come una coroutine, può invocare <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a>  quando è completato. I <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a> sono invocati nell'ordine nel quale sono registrati
</testo_normale>
<py_code>
# asyncio_future_callback.py
</py_code>
<testo_normale>
I <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a> dovrebbero attendersi un argomento, l'istanza di <code>Future</code>. Per passare argomenti addizionali, si usi <code>functools.partial()</code> per inglobarli.
</testo_normale>
<py_output>
$ python3 asyncio_future_callback.py
</py_output>
<titolo_2>
Eseguire Task in Concomitanza
</titolo_2>
<testo_normale>
I task (attività) costituiscono uno dei modi principali per interagire con il ciclo di eventi. I task inglobano <em>coroutine</em> e rilevano quando esse vengono completate. I <code>Task</code>  sono sottoclassi di <code>Future</code> quindi le altre coroutine possono attenderli e ciascuno di esse ha un risultato che può essere recuperato dopo che l'attività viene completata.
</testo_normale>
<titolo_3>
Far Partire un task
</titolo_3>
<testo_normale>
Per far partire un Task si usi <code>create_task()</code> per creare un istanza di <code>Task</code>. L'attività risultante verrà eseguita come parte delle operazioni concomitanti gestite dal ciclo di eventi fino a quando il ciclo è in esecuzione e la <em>coroutine</em> non ritorna.
</testo_normale>
<py_code>
# asyncio_create_task.py
</py_code>
<testo_normale>
Questo esempio attende che l'attività ritorni un risulato prima che la funzione <code>main()</code> esca.
</testo_normale>
<py_output>
$ python3 asyncio_create_task.py
</py_output>
<titolo_3>
Cancellare un Task
</titolo_3>
<testo_normale>
Mantenendo l'oggetto <code>Task</code> ritornato da <code>create_task()</code> è possibile cancellare l'operazione dell'attività prima che si completi.
</testo_normale>
<py_code>
# asyncio_cancel_task.py
</py_code>
<testo_normale>
Questo esempio crea, quindi cancella un task prima di far partire il ciclo di eventi. Il risultato è una eccezione <code>CancelledError</code> da <code>run_until_complete()</code>.
</testo_normale>
<py_output>
$ python3 asyncio_cancel_task.py
</py_output>
<testo_normale>
Se l'attività è cancellata mentre sta attendento un'altra operazione concomitante, viene notificata della cancellazione sollevando una eccezione <code>CancelledError</code> sollevata al punto di attesa.
</testo_normale>
<py_code>
# asyncio_cancel_task2.py
</py_code>
<testo_normale>
Catturando l'eccezione si ha una opportunità di pulire il lavoro già fatto, se necessario.
</testo_normale>
<py_output>
$ python3 asyncio_cancel_task2.py
</py_output>
<titolo_3>
Creare Task da Coroutine
</titolo_3>
<testo_normale>
La funzione <code>ensure_future()</code> ritorna un <code>Task</code> legato all'eseuzione di una <em>coroutine</em>. Quell'istanza di <code>Task</code> può essere quindi passata ad altro codice, il quale può attenderlo senza sapere come la <em>coroutine</em> originale sia stata costruita o chiamata.
</testo_normale>
<py_code>
# asyncio_ensure_future.py
</py_code>
<testo_normale>
Si noti che la <em>coroutine</em> data a <code>ensure_future()</code> non viene fatta partire fino a quando qualcosa usa <code>await</code> per consentirne l'esecuzione.
</testo_normale>
<py_output>
$ python3 asyncio_ensure_future.py
</py_output>
<titolo_2>
Comporre Coroutine con Strutture di Controllo
</titolo_2>
<testo_normale>
Il flusso di controllo lineare tra una serie di coroutine è facile da gestire con la parola chiave <em>built-in</em> <code>await</code>. E' anche possibile tramite strumenti in <strong>asyncio</strong> che strutture più complicate consentono a una <em>coroutine</em> di attendere che diverse altre siano completate in parallelo.
</testo_normale>
<titolo_3>
Attendere Multiple Coroutine
</titolo_3>
<testo_normale>
E' spesso utile dividere una operazione in diverse parti, quindi eseguirle separatamente. Ad esempio, per scaricare diverse risorse remote o interrogare API remote. In situazioni nelle quali l'ordine di esecuzione non importa, e dove ci potrebbe essere un arbitrario numero di operazioni, <code>wait()</code> può essere usato per mettere in pausa una <em>coroutine</em> fino a quando le altre operazioni siano completate.
</testo_normale>
<py_code>
# asyncio_wait.py
</py_code>
<testo_normale>
Internamente, <code>wait()</code> usa un <code>set</code> per mantenere le istanze di <code>Task</code> create. Ne consegue che esse sono attivate e completate in un ordine non prevedibile. Il valore di ritorno da <code>wait()</code>  è una tupla che contiene due insiemi che racchiudono le attività finite e in corso.
</testo_normale>
<py_output>
$ python3 asyncio_wait.py
</py_output>
<testo_normale>
Se <code>wait()</code> viene usato con un valore di <em>timeout</em> rimarranno solo le operazioni in corso.
</testo_normale>
<py_code>
# asyncio_wait_timeout.py
</py_code>
<testo_normale>
Le operazioni rimanenti dovrebbero essere cancellate oppure si dovrebbe attenderne il completamento. Lasciarle in corso mentre il ciclo di eventi continua farà sì che esse vengano eseguite in seguito, il che potrebbe essere non desiderabile se l'operazione generale viene considerata come abortita. Se si lasciano pendenti alla fine del processo verranno generati avvertimenti.
</testo_normale>
<py_output>
$ python3 asyncio_wait_timeout.py
</py_output>
<titolo_3>
Raccogliere i Risultati dalle Coroutine
</titolo_3>
<testo_normale>
Se le fasi sottostanti sono state ben definite, e solo i risultati di queste fasi hanno importanza, allora <code>gather()</code> potrebbe essere più utile per attendere operazioni multiple.
</testo_normale>
<py_code>
# asyncio_gather.py
</py_code>
<testo_normale>
Le attività create da <code>gather()</code> non sono esposte, in modo che non possano essere cancellate. IL valore di ritorno è una lista di risultati nello stesso ordine degli argomenti passati a <code>gather()</code>, a prescindere dall'ordine delle operazioni sottostanti effettivamente completate.
</testo_normale>
<py_output>
$ python3 asyncio_gather.py
</py_output>
<titolo_3>
Gestire le Operazioni Sottostanti Quando Finiscono
</titolo_3>
<testo_normale>
<code>as_completed()</code> è un genratore che gestisce l'esecuzione di una lista di <em>coroutine</em> fornitegli e produce i loro risultati uno alla volta non appena vengono completate. Come con <code>wait()</code>, l'ordine non è garantito da <code>as_completed()</code>, ma non è ncessario attendere che tutte le operazioni sottostanti siano completate prima di intraprendere altre azioni.
</testo_normale>
<py_code>
# asyncio_as_completed.py
</py_code>
<testo_normale>
Questo esempio fa partire parecchie fasi che finiscono in ordine inverso rispetto a quello di partenza. Mentre il generatore viene consumato, il ciclo attende il risultato della coroutine usando <code>await</code>.
</testo_normale>
<py_output>
$ python3 asyncio_as_completed.py
</py_output>
<titolo_2>
Sincronizzare i Primitivi
</titolo_2>
<testo_normale>
Sebbene le applicazioni <code>asyncio</code> in genere vengano eseguite in un processo a singolo <em>thread</em>, sono comunque costruite come applicazioni concorrenti. Ogni coroutine o <em>task</em> potrebbero essere eseguiti in un ordine non previsto, in base alle pause e agli <em>interrupt</em> da I/O e altri eventi esterni. Per supportare una concorrenzialità sicura, <code>asyncio</code> include implementazioni di alcuni degli stessi primitivi a basso livello che si trovano nei moduli <a href='threading.html' target='_blank'>threading</a> e <a href='multiprocessing.html' target='_blank'>multiprocessing</a>.
</testo_normale>
<titolo_3>
Bloccaggi (Locks)
</titolo_3>
<testo_normale>
Un <code>Lock</code> può essre usato per sorvegliare gli accessi a una risorsa condivisa. Solo il possessore del bloccaggio può usare la risorsa. I tentativi multipl di acquisire un bloccaggio verranno bloccati in modo che si sia un solo possessore alla volta
</testo_normale>
<py_code>
# asyncio_lock.py
</py_code>
<testo_normale>
Il metodo <code>acquire</code> per un bloccaggio può essere chiamato direttamente, usando <code>await</code> chiamando poi <code>release()</code> quando terminato (come in <code>colo2()</code> in questo esempio). Possono anche essere usati come gestori di contesto asincroni con le parole chiave <code>with await</code>, come in <code>coro1()</code>.
</testo_normale>
<py_output>
$ python3 asyncio_lock.py
</py_output>
<titolo_3>
Eventi
</titolo_3>
<testo_normale>
Un evento <code>asyncio.Event</code> è basato su <code>threading.Event</code>, e viene usato per consentire a molteplici consumatori di attendere che succeda qualcosa senza cercare un valore specifico da associare con la notifica.
</testo_normale>
<py_code>
# asyncio_event.py
</py_code>
<testo_normale>
Così come con <code>Lock</code>, sia <code>coro1()</code> che <code>coro2()</code> attendono che un evento sia impostato. La differenza è che entrambe possono partire non appeno lo stato dell'evento cambia, e non devono acquisire un possesso esclusivo sull'evento oggetto.
</testo_normale>
<py_output>
$ python3 asyncio_event.py
</py_output>
<titolo_3>
Condizioni
</titolo_3>
<testo_normale>
Una condizione (<code>condition</code>) funziona in modo simile a <code>Event</code> eccetto che invece che notificare a tutte le coroutine in attesa il numero di processi attivati viene controllato con un argomento per <code>notify()</code>.
</testo_normale>
<py_code>
# asyncio_condition.py
</py_code>
<testo_normale>
Questo esempio fa partire cinque consumantori di una <code>Condition</code>. Ognuno di essi usa il metodo <code>wait()</code> per attendere via notifica che possono procedere. <code>manipulate_condition()</code> notifica un consumatore, poi due, infine i restanti.
</testo_normale>
<py_output>
$ python3 asyncio_condition.py
</py_output>
<titolo_3>
Code
</titolo_3>
<testo_normale>
<code>asyncio.Queue</code> fornisce una struttura dati primo-che-entra, primo-che-esce per le coroutine come cosse una una coda <code>queue</code>. <code>Queue</code> fa quello per i <em>thread</em> quello che <code>multiprocessing.Queue</code> fa per i processi.
</testo_normale>
<py_code>
# asyncio_queue.py
</py_code>
<testo_normale>
Le operazioni di aggiunta o rimozione di elementi rispettivamente con <code>put()</code> e <code>get()</code> sono entrambe asincrone, visto che la dimensione della coda potrebbe essere fissa (bloccando una aggiunta) o la coda potrebbe essere vuota (bloccando una chiamata per ottenere un elemento)
</testo_normale>
<py_output>
$ python3 asyncio_queue.py
</py_output>
<titolo_2>
Input/Output Asincrono con Astrazioni del Protocollo di Classe
</titolo_2>
<testo_normale>
Fino a questo punto gli esempi hanno tutti evitato di mischiare concorrenza e operazioni I/O per focalizzarsi su un concetto alla votla. Tuttavia lo scambio di contesti con bloccaggi di I/O è uno dei casi di uso primari per <code>asyncio</code>. Basata su concetti di concorrenza già introdotti, questa sezione esamina due programmi di esempio che implementano un semplice server e client che ripetono quanto ricevuto, simili agli esempi usati per <a href='socket.html' target='_blank'>socket</a> e <a href='socketserver' target='_blank'>socketserver</a>. Un client può connettersi al server, inviare dati, quindi ricevere gli stessi dati in risposta. Ogni volta che viene iniziata una opearazione I/O, il codice in esecuzione passa il controllo al ciclo di eventi, consentendo l'esecuzione di altre attività fino a che l'I/O è pronto.
</testo_normale>
<titolo_3>
Server Che Invia Quanto Ricevuto
</titolo_3>
<testo_normale>
Il server inizia importando i moduli che gli servono per impostare <code>asyncio</code> e <a href='logging.html' target='_blank'>logging</a>, quindi crea un oggetto ciclo di eventi.
</testo_normale>
<py_code>
# asyncio_echo_server_protocol.py

import asyncio
import logging
import sys

SERVER_ADDRESS = ('localhost', 10000)

logging.basicConfig(
    level=logging.DEBUG,
    format='%(name)s: %(message)s',
    stream=sys.stderr,
)
log = logging.getLogger('main')

event_loop = asyncio.get_event_loop()
</py_code>
<testo_normale>
Quindi definisce una sottoclasse di <code>asyncio.Protocol</code> per gestire la comunicazione con il client. I metodi dell'oggetto protocollo sono chiamati in base agli eventi associati con il <em>socket</em> del server
</testo_normale>
<py_code>
class EchoServer(asyncio.Protocol):
</py_code>
<testo_normale>
Ogni nuova connessione client attiva una chiamata a <code>connection_made()</code>. L'argomento <code>transport</code> è una istanza di <code>asyncio.Transport</code>, che fornisce una astrazione per eseguire I/O asincrono usando il <em>socket</em>. Diversi tipi di comunicazione forniscono diverse implementazioni del trasporto, tutte con la stessa API. Ad esempio ci sono classi di trasporto separate per lavorare con i <em>socket</em> e per lavorare con <em>pipe</em> per i sottoprocessi. L'indirizzo del client in arrivo è disponibile dal trasporto tramite <code>get_extra_info()</code>, un metodo specifico all'imolementazione.
</testo_normale>
<py_code>
    def connection_made(self, transport):
        self.transport = transport
        self.address = transport.get_extra_info('peername')
        self.log = logging.getLogger(
            'EchoServer_{}_{}'.format(*self.address)
        )
        self.log.debug('connessione accetata')
</py_code>
<testo_normale>
Dopo che viene stabilita una connessione, quando vengono spediti dati dal client al server, viene invocato il metodo del protocollo <code>data_received()</code> per passare i dati da elaborar. I dati sono passati come stringa di <em>byte</em>, e spetta all'applicazione la decodifica nel modo appropriato. Qui il risultato viene registrato, quindi viene ritornata una risposta immediata al client tramite <code>transport.write()</code>.
</testo_normale>
<py_code>
    def data_received(self, data):
        self.log.debug('ricevuto {!r}'.format(data))
        self.transport.write(data)
        self.log.debug('inviato {!r}'.format(data))
</py_code>
<testo_normale>
Alcuni trasporti supportano un indicatore speciale di fine file ("EOF"). Quando viene rilevato un EOF, viene chiamato il metodo <code>eof_received()</code>. In questa implementazione, EOF viene restituito al client per indicare che è stato ricevuto. Visto che non tutti i trasporti supportano un EOF esplicito, questo protocollo chiede prima al trasporto se sia sicuro inviare un EOF.
</testo_normale>
<py_code>
    def eof_received(self):
        self.log.debug('ricevuto EOF')
        if self.transport.can_write_eof():
            self.transport.write_eof()
</py_code>
<testo_normale>
Quando viene chiusa una connessione, sia normalmente che a causa di un errore, il metodo del protocollo <code>connection_lost()</code> viene chiamato. Se si era verificato un errore, l'argomento contiene un oggetto eccezione appropriato. Altrimenti è <code>None</code>.
</testo_normale>
<py_code>
    def connection_lost(self, error):
        if error:
            self.log.error('ERRORE: {}'.format(error))
        else:
            self.log.debug('chiusura')
        super().connection_lost(error)
</py_code>
<testo_normale>
Ci sono due passi da compiere per far partire il server. Prima l'applicazione dice al ciclo di eventi di creare un nuovo oggetto server usando il protocollo di classe, il nome host e il <em>socket</em> sul quale è in ascolto. Il metodo <code>create_server()</code> è una coroutine, quindi i risultati devono essere elaborati dal ciclo di eventi in ordine per far veramente partire il server. Il completamento della coroutine produce una istanza di <code>asyncio.Server</code> legata al ciclo di eventi.
</testo_normale>
<py_code>
# Crea il server e lasci che il ciclo finisca la coroutine prima di far
# partire il vero ciclo di eventi.
factory = event_loop.create_server(EchoServer, *SERVER_ADDRESS)
server = event_loop.run_until_complete(factory)
log.debug('in partenza on {} porta {}'.format(*SERVER_ADDRESS))
</py_code>
<testo_normale>
Il ciclo di eventi poi deve esser eseguito nell'ordine per elaborare eventi e gestire le richieste del client. Per un servizio che debba restare in esecuione per lungo tempo, il metodo <code>run_forever()</code> è il modo più semplice per farlo. Quando viene arrestato un ciclo di eventi, sia dal codice applicativo che da un segnale inviato al processo, il server può essere chiuso per pulire correttamente il <em>socket</em>, quindi il ciclo di eventi può essere chiuso per terminare la gestione di altre coroutine prima che il programma esca.
</testo_normale>
<py_code>
# Entra nel ciclo di eventi in modo permanente per gestire tutte le connessioni
try:
    event_loop.run_forever()
finally:
    log.debug('chiusura del server')
    server.close()
    event_loop.run_until_complete(server.wait_closed())
    log.debug('chiusura del ciclo di eventi')
    event_loop.close()
</py_code>
<titolo_3>
Client Che Riceve Quanto Inviato
</titolo_3>
<testo_normale>

</testo_normale>
<vedi_anche>
https://docs.python.org/3.5/library/multiprocessing.html|multiprocessing|La documentazione della libreria standard per questo modulo.
threading.html|threading|API di alto livello per lvaorare con i thread
https://it.wikipedia.org/wiki/MapReduce|MapReduce - Wikipedia|Panoramica di MapReduce su Wikipedia
http://research.google.com/archive/mapreduce.html|MapReduce: Simplified Dsta Processing on Large Clusters| Presentazione e documento su MapReduce da parte di Google Labs
operator.html|Operator|Strumenti sugli operatori tipo <code>itemgetter</code>
</vedi_anche>
</documento_tradotto>
