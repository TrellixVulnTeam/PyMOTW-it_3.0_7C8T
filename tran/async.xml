<xml version="1.0" encoding="Latin-1"?>
<target>3</target>
<categoria>Concomitanza con processi, thread e coroutines</categoria>
<documento_tradotto>
<titolo_1>
asyncio - I/O Asincrono, ciclo di eventi e strumenti per la gestione della concorrenza
</titolo_1>
<descrizione>
Una infrastruttura per I/O asincrono e concorrenza

</descrizione>
<testo_normale>
Il modulo <strong>asyncio</strong> fornisce strumenti per costruire applicazioni concorrenti usando <em>coroutine</em>. Mentre il modulo <a href='threading.html' target='_blank'>threading</a> implementa la concorrenza attraverso <em>thread</em> di applicazione e <a href='multiprocessing.html' target='_blank'>multiprocessing</a> implementa la concorrenza usando processi di sistema, <strong>asyncio</strong> usa un approccio a <em>thread</em> singolo e processo singolo nel quale parti di un'applicazione cooperano per passarsi a compiti esplicitamente con tempistiche ottimali. Molto spesso questo contesto di scambio accade quando il programma sarebbe altrimenti bloccato in attesa di leggere o scrivere dati, m <strong>asyncio</strong> include anche il supporto per pianificare l'esecuzione di codice ad una specifico spazio temporale futuro, per abilitare una <em>coroutine</em> ad attendere che un'altra si completi, per gestire segnali di sistema e per riconoscere altri eventi che possano costituire una ragione per un'applicazione per modificare quello su cui sta lavorando.
</testo_normale>
<titolo_2>
Concetti di Concorrenza Asincrona
</titolo_2>
<testo_normale>
La maggior parte dei programmi che usano altri modelli di concorrenza sono scritti linearmente, e fanno affidamento sulla gestione del <em>thread</em> o del processo del linguaggio in fase di esecuzione o del sistema operativo per cambiare contesto quando appropriato. Una applicazione basata su <code>asyncio</code> richiede che il suo codice gestisca esplicitamente i cambi di contesto, ed usare tecniche per fare questo correttamente dipende dalla comprensione di parecchi concetti interdipendenti.
</testo_normale>
<testo_normale>
L'infrastruttura fornita da <strong>asyncio</strong> è centrata su di un <em>ciclo di eventi</em> (event loop), un oggetto di prima classe responsabile per la gestione efficiente degli eventi I/O, eventi di sistema e cambiamenti di contesto di applicazioni. Sono fornite parecchie implementazioni del ciclo per trarre vantaggio con efficienza delsyla capacità del sistema operativo. Mentre una impostazione predefinita ragionevole è di solito selezionata automaticamente, è anche possibile scegliere una implementazione particolare del ciclo di eventi all'interno dell'applicazione. Questo è utile sotto Windows, ad esempio, dove alcune classi di ciclo aggiungono supporto per processi esterni in un modo nel quale ne potrebbe beneficiare un ambiente I/O di rete.
</testo_normale>
<testo_normale>
Una applicazione interagisce con il ciclo di eventi in modo esplicito registrando il codice da eseguirsi, e lascia che il ciclo di eventi faccia le chiamate necessarie all'interno del codice dell'applicazione quando le risorse sono disponibili. Ad esempio un server di rete apre dei <em>socket</em>, quindi li registra per potere essere notificato quando su di essi si manifestano degli eventi di input. Il ciclo di eventi allerta il codice del server quando vi è una connessione in arrivo o quando ci sono dati da leggere. Ci si attende che il codice dell'applicazione riguadagni il controllo nuovamente dopo un breve periodo di tempo quando non c'è più lavoro da fare nel contesto corrente. Ad esempio se non ci sono più dati da leggere da un socket il server dovrebbe riaffidare il controllo al ciclo di eventi.
</testo_normale>
<testo_normale>
Il meccanismo per restituire il controllo al ciclo di eventi dipende dalle <em>coroutine</em> di Python, esse sono funzioni speciali per restituire il controllo al chiamante senza perdere il proprio stato. Le <em>coroutine</em> sono simili alle funzioni generatore, ad in effetti si possono usare generatori per implementare le <em>coroutine</em> in versioni di Python inferiori alla 3.5 senza il supporto nativo degli oggetti di <em>coroutine</em>. <strong>asyncio</strong> fornisce anche uno strato di astrazione basato su classi per protocolli e <em>trasporti</em> per scrivere codice usando <em>callback</em> invece di scrivere direttamente <em>coroutine</em>. In entrambi i modelli basati su classi e <em>coroutine</em> modificando esplicitamente il contesto ritornando nel ciclo di eventi equivale ad una implicita implementazione dei <em>threading</em> di Python per il cambio di contesto.
</testo_normale>
<testo_normale>
Un <em>future</em> è una struttura dati che rappresenta il risultato di un lavoro che non è ancora stato completato. Il ciclo di eventi può monitorare un oggetto <code>Future</code> per vedere quando viene impostato come ultimato, consentendo ad una parte di applicazione di attendere che un'altra parte finisca un lavoro. A parte i <em>future</em>, <strong>asyncio</strong> fornisce altri primitivi di concorrenzialità come i bloccaggi (<em>locks</em>) e i semafori.
</testo_normale>
<testo_normale>
Un <em>task</em> (compito) è una sottoclasse di <code>Future</code> che sa come impacchettare e gestire l'esecuzione per una <em>coroutine</em>. I <em>task</em> possono essere pianificati con un ciclo di eventi per essere eseguiti quando le risorse a essi necessarie sono disponibili, a per prodrurre un risultato che può essere consumato da altre <em>coroutine</em>.
</testo_normale>
<titolo_2>
Multiasking Cooperativo con Coroutine
</titolo_2>
<testo_normale>
Le <em>coroutine</em> sono un costrutto di linguaggio progettato per operazioni concorrenti. Una funzione <em>coroutine</em> crea un oggetto <em>coroutine</em> quando chiamata, poi il chiamante può eseguire il codice della funzione usando il metodo della <em>coroutine</em> <code>send()</code>. Una <em>coroutine</em> può mettere in pausa l'esecuzione usando la parola chiave <code>await</code> con un'altra <em>coroutine</em>. Mentre è il pausa, lo stato della <em>coroutine</em> viene mantenuto, in modo che possa essere ripreso dove era stato lasciato la prossima volta che viene chiamata in causa.
</testo_normale>
<titolo_3>
Fare Partire una Coroutine
</titolo_3>
<testo_normale>
Ci sono alcuni modi diversi per fare in modo che un ciclo di eventi <code>asyncio</code> faccia partire una <em>coroutine</em>. Quello più semplice è usare <code>run_until_complete()</code>, passandogli la <em>coroutine</em> direttamente.
</testo_normale>
<py_code>
# asyncio_coroutine.py
</py_code>
<testo_normale>
Il primo passo è ottenere un riferimento al ciclo di eventi. Può essere usato il tipo di ciclo predefinito, oppure può essere istanziata una classe di ciclo specifica. In questo esempio, si usa il ciclo predefinito. Il metodo <code>run_until_complete()</code> fa partire il ciclo con l'oggetto <em>coroutine</em> ed interrompe il ciclo quando la <em>coroutine</em> esce ritornando.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine.py
</py_output>
<titolo_3>
Ritornare Valori da Coroutine
</titolo_3>
<testo_normale>
Il valore di ritorno di una <em>coroutine</em> viene passato al codice che la fa partire e lo attende.
</testo_normale>
<py_code>
# asyncio_coroutine_return.py
</py_code>
<testo_normale>
In questo caso <code>run_until_complete</code> ritorna anche il risultato che la coroutine sta attendendo.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine_return.py
</py_output>
<titolo_3>
Concatenare Coroutine
</titolo_3>
<testo_normale>
Una coroutine può far partire un'altra coroutine ed attenderne il risultato. Questo facilita la suddivisione  di un compito in parti riutilizzabili. L'esempio seguente ha due fasi che devono essere eseguite in ordine, ma che possono essere eseguite concorrenzialmente con altre opearazioni
</testo_normale>
<py_code>
# asyncio_coroutine_chain.py
</py_code>
<testo_normale>
La parola chiave <code>await</code> viene usata invece che aggiungere le nuove coroutine al ciclo, poichè il flusso di controllo è già all'interno di una coroutine che è gestita da ciclo non è necessario dire al ciclo di gestire la nuova coroutine.
</testo_normale>
<py_output>
$ python3 asyncio_coroutine_chain.py
</py_output>
<titolo_3>
Generatori Invece che Coroutine
</titolo_3>
<testo_normale>
Le funzioni coroutine sono una componente chiave della progettazione di <strong>asyncio</strong>. Esse forniscono un costrutto di linugaggio per interrompere l'esecuzione di parti di un programm, preservando lo stato di quella chiamate, e rientrando in quello stato successivamente, tutte importanti capacità per una infrastruttura di concorrenzialità.
</testo_normale>
<testo_normale>
Python 3.5 ha intradotto nuove caratteristiche di linguaggio per definire nativamente dette coroutine usando <code>async def</code> e per mantenere il controllo usando <code>await</code>. Gli esempio per <strong>asyncio</strong> traggono vantaggio dalle nuove caratteristiche. Versioni precedenti di Python 3 possono usare funzioni generatore impacchetate con il decoratore <code>asyncio.coroutine()</code> e <code>yield from</code> per ottenere lo stesso effetto.
</testo_normale>
<py_code>
# asyncio_generator.py
</py_code>
<testo_normale>
L'esempio precedente riproduce <code>asyncio_coroutine_chain.py</code> usando funzioni generatore in luogo di coroutine native.
</testo_normale>
<py_output>
$ python3 asyncio_generator.py
</py_output>
<titolo_2>
Pianificare Chiamate a Funzioni Normali
</titolo_2>
<testo_normale>
Oltre a gestire coroutine e <em>callback</em> I/O, il ciclo di eventi di <strong>asyncio</strong> può pianificare chiamate a funzioni normli in base al valore di temporizzazione conservato nel ciclo
</testo_normale>
<titolo_3>
Pianificare un Callback "Presto"
</titolo_3>
<testo_normale>
Se la tempistica del callback non importa, <code>call_soon()</code> può essere usato per pianificare la chiamata per la successiva iterazione del ciclo. Qualunque altro argomento posizionale dopo la funzione viene passato al <em>callback</em> quando viene invocato. Per passare argomenti nominali al <em>callback</em> si usi <code>partial()</code> dal modulo <a href='functools.html' target='_blank'>functools</a>.
</testo_normale>
<py_code>
# asyncio_call_soon.py
</py_code>
<testo_normale>
I <em>callback</em> sono invocati nell'ordine nel quale sono pianificati.
</testo_normale>
<py_output>
$ python3 asyncio_call_soon.py
</py_output>
<titolo_3>
Pianificare un Callback per uno Specifico Orario
</titolo_3>
<testo_normale>
E' anche possibile pianificare una chiamata ad uno specifico orario. Il ciclo usa un orologio monotonico, invece che un orologio "da muro", per assicurarsi che il valore di "adesso" non regredisca mai. Per scegliere un orario per un <em>callback</em> pianificato, è necessario partire dallo stato interno di quell'orologio usando il metodo del ciclo <code>time()</code>.
</testo_normale>
<py_code>
# asyncio_call_at.py
</py_code>
<testo_normale>
Si noti che il tempo secondo il ciclo non corrisponde al valore ritornato da <code>time.time()</code>
</testo_normale>
<py_output>
$ python3 asyncio_call_at.py
</py_output>
<titolo_2>
Produrre Risultati In Modo Asincrono
</titolo_2>
<testo_normale>
Un <code>Future</code> rappresenta il risultato di un lavoro che non è ancora stato completato. Il ciclo di eventi può osservare lo stato di un oggetto <code>Future</code> per verificare quando questo è terminato, consentendo a una parte di applicazione di attendere che un'altra finisca una qualche attività
</testo_normale>
<py_code>
# asyncio_future_event_loop.py
</py_code>
<testo_normale>
Lo stato delle modifiche di un <code>Future</code> cambia a completato quando <code>set_result()</code> viene chiamato e l'istanza di <code>Future</code> trattiene il risultato dabo al metodo per recuperarlo successivamente.
</testo_normale>
<py_output>
$ python3 asyncio_future_event_loop.py
</py_output>
<testo_normale>
Un <code>Future</code> può anche essere usato con la parola chiave <code>await</code>, come in questo esempio
</testo_normale>
<py_code>
# asyncio_future_await.py
</py_code>
<testo_normale>
Il risultato del <code>Future</code> viene ritornato da <code>await</code>, quindi è spesso possibile avere lo stesso codice che funziona sia con una <em>coroutine</em> normale che con una istanza di <code>Future</code>.
</testo_normale>
<py_output>
$ python3 asyncio_future_await.py
</py_output>
<titolo_3>
Callaback di Future
</titolo_3>
<testo_normale>
Un <code>Future</code>, oltre che lavorare come una coroutine, può invocare <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a>  quando è completato. I <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a> sono invocati nell'ordine nel quale sono registrati
</testo_normale>
<py_code>
# asyncio_future_callback.py
</py_code>
<testo_normale>
I <a href='https://www.wikiwand.com/it/Callback' target='_blank'><em>callback</em></a> dovrebbero attendersi un argomento, l'istanza di <code>Future</code>. Per passare argomenti addizionali, si usi <code>functools.partial()</code> per inglobarli.
</testo_normale>
<py_output>
$ python3 asyncio_future_callback.py
</py_output>
<titolo_2>
Eseguire Task in Concomitanza
</titolo_2>
<testo_normale>
I task (attività) costituiscono uno dei modi principali per interagire con il ciclo di eventi. I task inglobano <em>coroutine</em> e rilevano quando esse vengono completate. I <code>Task</code>  sono sottoclassi di <code>Future</code> quindi le altre coroutine possono attenderli e ciascuno di esse ha un risultato che può essere recuperato dopo che l'attività viene completata.
</testo_normale>
<titolo_3>
Far Partire un task
</titolo_3>
<testo_normale>
Per far partire un Task si usi <code>create_task()</code> per creare un istanza di <code>Task</code>. L'attività risultante verrà eseguita come parte delle operazioni concomitanti gestite dal ciclo di eventi fino a quando il ciclo è in esecuzione e la <em>coroutine</em> non ritorna.
</testo_normale>
<py_code>
# asyncio_create_task.py
</py_code>
<testo_normale>
Questo esempio attende che l'attività ritorni un risulato prima che la funzione <code>main()</code> esca.
</testo_normale>
<py_output>
$ python3 asyncio_create_task.py
</py_output>
<titolo_3>
Cancellare un Task
</titolo_3>
<testo_normale>
Mantenendo l'oggetto <code>Task</code> ritornato da <code>create_task()</code> è possibile cancellare l'operazione dell'attività prima che si completi.
</testo_normale>
<py_code>
# asyncio_cancel_task.py
</py_code>
<testo_normale>
Questo esempio crea, quindi cancella un task prima di far partire il ciclo di eventi. Il risultato è una eccezione <code>CancelledError</code> da <code>run_until_complete()</code>.
</testo_normale>
<py_output>
$ python3 asyncio_cancel_task.py
</py_output>
<testo_normale>
Se l'attività è cancellata mentre sta attendento un'altra operazione concomitante, viene notificata della cancellazione sollevando una eccezione <code>CancelledError</code> sollevata al punto di attesa.
</testo_normale>
<py_code>
# asyncio_cancel_task2.py
</py_code>
<testo_normale>
Catturando l'eccezione si ha una opportunità di pulire il lavoro già fatto, se necessario.
</testo_normale>
<py_output>
$ python3 asyncio_cancel_task2.py
</py_output>
<titolo_3>
Creare Task da Coroutine
</titolo_3>
<testo_normale>
La funzione <code>ensure_future()</code> ritorna un <code>Task</code> legato all'eseuzione di una <em>coroutine</em>. Quell'istanza di <code>Task</code> può essere quindi passata ad altro codice, il quale può attenderlo senza sapere come la <em>coroutine</em> originale sia stata costruita o chiamata.
</testo_normale>
<py_code>
# asyncio_ensure_future.py
</py_code>
<testo_normale>
Si noti che la <em>coroutine</em> data a <code>ensure_future()</code> non viene fatta partire fino a quando qualcosa usa <code>await</code> per consentirne l'esecuzione.
</testo_normale>
<py_output>
$ python3 asyncio_ensure_future.py
</py_output>
<titolo_2>
Comporre Coroutine con Strutture di Controllo
</titolo_2>
<testo_normale>
Il flusso di controllo lineare tra una serie di coroutine è facile da gestire con la parola chiave <em>built-in</em> <code>await</code>. E' anche possibile tramite strumenti in <strong>asyncio</strong> che strutture più complicate consentono a una <em>coroutine</em> di attendere che diverse altre siano completate in parallelo.
</testo_normale>
<titolo_3>
Attendere Multiple Coroutine
</titolo_3>
<testo_normale>
E' spesso utile dividere una operazione in diverse parti, quindi eseguirle separatamente. Ad esempio, per scaricare diverse risorse remote o interrogare API remote. In situazioni nelle quali l'ordine di esecuzione non importa, e dove ci potrebbe essere un arbitrario numero di operazioni, <code>wait()</code> può essere usato per mettere in pausa una <em>coroutine</em> fino a quando le altre operazioni siano completate.
</testo_normale>
<py_code>
# asyncio_wait.py
</py_code>
<testo_normale>
Internamente, <code>wait()</code> usa un <code>set</code> per mantenere le istanze di <code>Task</code> create. Ne consegue che esse sono attivate e completate in un ordine non prevedibile. Il valore di ritorno da <code>wait()</code>  è una tupla che contiene due insiemi che racchiudono le attività finite e in corso.
</testo_normale>
<py_output>
$ python3 asyncio_wait.py
</py_output>
<testo_normale>
Se <code>wait()</code> viene usato con un valore di <em>timeout</em> rimarranno solo le operazioni in corso.
</testo_normale>
<py_code>
# asyncio_wait_timeout.py
</py_code>
<testo_normale>
Le operazioni rimanenti dovrebbero essere cancellate oppure si dovrebbe attenderne il completamento. Lasciarle in corso mentre il ciclo di eventi continua farà sì che esse vengano eseguite in seguito, il che potrebbe essere non desiderabile se l'operazione generale viene considerata come abortita. Se si lasciano pendenti alla fine del processo verranno generati avvertimenti.
</testo_normale>
<py_output>
$ python3 asyncio_wait_timeout.py
</py_output>
<titolo_3>
Raccogliere i Risultati dalle Coroutine
</titolo_3>
<testo_normale>
Se le fasi sottostanti sono state ben definite, e solo i risultati di queste fasi hanno importanza, allora <code>gather()</code> potrebbe essere più utile per attendere operazioni multiple.
</testo_normale>
<py_code>
# asyncio_gather.py
</py_code>
<testo_normale>
Le attività create da <code>gather()</code> non sono esposte, in modo che non possano essere cancellate. IL valore di ritorno è una lista di risultati nello stesso ordine degli argomenti passati a <code>gather()</code>, a prescindere dall'ordine delle operazioni sottostanti effettivamente completate.
</testo_normale>
<py_output>
$ python3 asyncio_gather.py
</py_output>
<titolo_3>
Gestire le Operazioni Sottostanti Quando Finiscono
</titolo_3>
<testo_normale>
<code>as_completed()</code> è un genratore che gestisce l'esecuzione di una lista di <em>coroutine</em> fornitegli e produce i loro risultati uno alla volta non appena vengono completate. Come con <code>wait()</code>, l'ordine non è garantito da <code>as_completed()</code>, ma non è ncessario attendere che tutte le operazioni sottostanti siano completate prima di intraprendere altre azioni.
</testo_normale>
<py_code>
# asyncio_as_completed.py
</py_code>
<testo_normale>
Questo esempio fa partire parecchie fasi che finiscono in ordine inverso rispetto a quello di partenza. Mentre il generatore viene consumato, il ciclo attende il risultato della coroutine usando <code>await</code>.
</testo_normale>
<py_output>
$ python3 asyncio_as_completed.py
</py_output>
<titolo_2>
Sincronizzare i Primitivi
</titolo_2>
<testo_normale>
Sebbene le applicazioni <code>asyncio</code> in genere vengano eseguite in un processo a singolo <em>thread</em>, sono comunque costruite come applicazioni concorrenti. Ogni coroutine o <em>task</em> potrebbero essere eseguiti in un ordine non previsto, in base alle pause e agli <em>interrupt</em> da I/O e altri eventi esterni. Per supportare una concorrenzialità sicura, <code>asyncio</code> include implementazioni di alcuni degli stessi primitivi a basso livello che si trovano nei moduli <a href='threading.html' target='_blank'>threading</a> e <a href='multiprocessing.html' target='_blank'>multiprocessing</a>.
</testo_normale>
<titolo_3>
Bloccaggi (Locks)
</titolo_3>
<testo_normale>
Un <code>Lock</code> può essre usato per sorvegliare gli accessi a una risorsa condivisa. Solo il possessore del bloccaggio può usare la risorsa. I tentativi multipl di acquisire un bloccaggio verranno bloccati in modo che si sia un solo possessore alla volta
</testo_normale>
<py_code>
# asyncio_lock.py
</py_code>
<testo_normale>
Il metodo <code>acquire</code> per un bloccaggio può essere chiamato direttamente, usando <code>await</code> chiamando poi <code>release()</code> quando terminato (come in <code>colo2()</code> in questo esempio). Possono anche essere usati come gestori di contesto asincroni con le parole chiave <code>with await</code>, come in <code>coro1()</code>.
</testo_normale>
<py_output>
$ python3 asyncio_lock.py
</py_output>
<titolo_3>
Eventi
</titolo_3>
<testo_normale>
Un evento <code>asyncio.Event</code> è basato su <code>threading.Event</code>, e viene usato per consentire a molteplici consumatori di attendere che succeda qualcosa senza cercare un valore specifico da associare con la notifica.
</testo_normale>
<py_code>
# asyncio_event.py
</py_code>
<testo_normale>
Così come con <code>Lock</code>, sia <code>coro1()</code> che <code>coro2()</code> attendono che un evento sia impostato. La differenza è che entrambe possono partire non appeno lo stato dell'evento cambia, e non devono acquisire un possesso esclusivo sull'evento oggetto.
</testo_normale>
<py_output>
$ python3 asyncio_event.py
</py_output>
<titolo_3>
Condizioni
</titolo_3>
<testo_normale>
Una condizione (<code>condition</code>) funziona in modo simile a <code>Event</code> eccetto che invece che notificare a tutte le coroutine in attesa il numero di processi attivati viene controllato con un argomento per <code>notify()</code>.
</testo_normale>
<py_code>
# asyncio_condition.py
</py_code>
<testo_normale>
Questo esempio fa partire cinque consumantori di una <code>Condition</code>. Ognuno di essi usa il metodo <code>wait()</code> per attendere via notifica che possono procedere. <code>manipulate_condition()</code> notifica un consumatore, poi due, infine i restanti.
</testo_normale>
<py_output>
$ python3 asyncio_condition.py
</py_output>
<titolo_3>
Code
</titolo_3>
<testo_normale>
<code>asyncio.Queue</code> fornisce una struttura dati primo-che-entra, primo-che-esce per le coroutine come cosse una una coda <code>queue</code>. <code>Queue</code> fa quello per i <em>thread</em> quello che <code>multiprocessing.Queue</code> fa per i processi.
</testo_normale>
<py_code>
# asyncio_queue.py
</py_code>
<testo_normale>
Le operazioni di aggiunta o rimozione di elementi rispettivamente con <code>put()</code> e <code>get()</code> sono entrambe asincrone, visto che la dimensione della coda potrebbe essere fissa (bloccando una aggiunta) o la coda potrebbe essere vuota (bloccando una chiamata per ottenere un elemento)
</testo_normale>
<py_output>
$ python3 asyncio_queue.py
</py_output>
<titolo_2>
Input/Output Asincrono con Astrazioni del Protocollo di Classe
</titolo_2>
<testo_normale>
Fino a questo punto gli esempi hanno tutti evitato di mischiare concorrenza e operazioni I/O per focalizzarsi su un concetto alla votla. Tuttavia lo scambio di contesti con bloccaggi di I/O è uno dei casi di uso primari per <code>asyncio</code>. Basata su concetti di concorrenza già introdotti, questa sezione esamina due programmi di esempio che implementano un semplice server e client che ripetono quanto ricevuto, simili agli esempi usati per <a href='socket.html' target='_blank'>socket</a> e <a href='socketserver' target='_blank'>socketserver</a>. Un client può connettersi al server, inviare dati, quindi ricevere gli stessi dati in risposta. Ogni volta che viene iniziata una opearazione I/O, il codice in esecuzione passa il controllo al ciclo di eventi, consentendo l'esecuzione di altre attività fino a che l'I/O è pronto.
</testo_normale>
<titolo_3>
Server Che Invia Quanto Ricevuto
</titolo_3>
<testo_normale>
Il server inizia importando i moduli che gli servono per impostare <code>asyncio</code> e <a href='logging.html' target='_blank'>logging</a>, quindi crea un oggetto ciclo di eventi.
</testo_normale>
<py_code>
# asyncio_echo_server_protocol.py

import asyncio
import logging
import sys

SERVER_ADDRESS = ('localhost', 10000)

logging.basicConfig(
    level=logging.DEBUG,
    format='%(name)s: %(message)s',
    stream=sys.stderr,
)
log = logging.getLogger('main')

event_loop = asyncio.get_event_loop()
</py_code>
<testo_normale>
Quindi definisce una sottoclasse di <code>asyncio.Protocol</code> per gestire la comunicazione con il client. I metodi dell'oggetto protocollo sono chiamati in base agli eventi associati con il <em>socket</em> del server
</testo_normale>
<py_code>
class EchoServer(asyncio.Protocol):
</py_code>
<testo_normale>
Ogni nuova connessione client attiva una chiamata a <code>connection_made()</code>. L'argomento <code>transport</code> è una istanza di <code>asyncio.Transport</code>, che fornisce una astrazione per eseguire I/O asincrono usando il <em>socket</em>. Diversi tipi di comunicazione forniscono diverse implementazioni del trasporto, tutte con la stessa API. Ad esempio ci sono classi di trasporto separate per lavorare con i <em>socket</em> e per lavorare con <em>pipe</em> per i sottoprocessi. L'indirizzo del client in arrivo è disponibile dal trasporto tramite <code>get_extra_info()</code>, un metodo specifico all'imolementazione.
</testo_normale>
<py_code>
    def connection_made(self, transport):
        self.transport = transport
        self.address = transport.get_extra_info('peername')
        self.log = logging.getLogger(
            'EchoServer_{}_{}'.format(*self.address)
        )
        self.log.debug('connessione accetata')
</py_code>
<testo_normale>
Dopo che viene stabilita una connessione, quando vengono spediti dati dal client al server, viene invocato il metodo del protocollo <code>data_received()</code> per passare i dati da elaborar. I dati sono passati come stringa di <em>byte</em>, e spetta all'applicazione la decodifica nel modo appropriato. Qui il risultato viene registrato, quindi viene ritornata una risposta immediata al client tramite <code>transport.write()</code>.
</testo_normale>
<py_code>
    def data_received(self, data):
        self.log.debug('ricevuto {!r}'.format(data))
        self.transport.write(data)
        self.log.debug('inviato {!r}'.format(data))
</py_code>
<testo_normale>
Alcuni trasporti supportano un indicatore speciale di fine file ("EOF"). Quando viene rilevato un EOF, viene chiamato il metodo <code>eof_received()</code>. In questa implementazione, EOF viene restituito al client per indicare che è stato ricevuto. Visto che non tutti i trasporti supportano un EOF esplicito, questo protocollo chiede prima al trasporto se sia sicuro inviare un EOF.
</testo_normale>
<py_code>
    def eof_received(self):
        self.log.debug('ricevuto EOF')
        if self.transport.can_write_eof():
            self.transport.write_eof()
</py_code>
<testo_normale>
Quando viene chiusa una connessione, sia normalmente che a causa di un errore, il metodo del protocollo <code>connection_lost()</code> viene chiamato. Se si era verificato un errore, l'argomento contiene un oggetto eccezione appropriato. Altrimenti è <code>None</code>.
</testo_normale>
<py_code>
    def connection_lost(self, error):
        if error:
            self.log.error('ERRORE: {}'.format(error))
        else:
            self.log.debug('chiusura')
        super().connection_lost(error)
</py_code>
<testo_normale>
Ci sono due passi da compiere per far partire il server. Prima l'applicazione dice al ciclo di eventi di creare un nuovo oggetto server usando il protocollo di classe, il nome host e il <em>socket</em> sul quale è in ascolto. Il metodo <code>create_server()</code> è una coroutine, quindi i risultati devono essere elaborati dal ciclo di eventi in ordine per far veramente partire il server. Il completamento della coroutine produce una istanza di <code>asyncio.Server</code> legata al ciclo di eventi.
</testo_normale>
<py_code>
# Crea il server e lasci che il ciclo finisca la coroutine prima di far
# partire il vero ciclo di eventi.
factory = event_loop.create_server(EchoServer, *SERVER_ADDRESS)
server = event_loop.run_until_complete(factory)
log.debug('in partenza on {} porta {}'.format(*SERVER_ADDRESS))
</py_code>
<testo_normale>
Il ciclo di eventi poi deve esser eseguito nell'ordine per elaborare eventi e gestire le richieste del client. Per un servizio che debba restare in esecuione per lungo tempo, il metodo <code>run_forever()</code> è il modo più semplice per farlo. Quando viene arrestato un ciclo di eventi, sia dal codice applicativo che da un segnale inviato al processo, il server può essere chiuso per pulire correttamente il <em>socket</em>, quindi il ciclo di eventi può essere chiuso per terminare la gestione di altre coroutine prima che il programma esca.
</testo_normale>
<py_code>
# Entra nel ciclo di eventi in modo permanente per gestire tutte le connessioni
try:
    event_loop.run_forever()
finally:
    log.debug('chiusura del server')
    server.close()
    event_loop.run_until_complete(server.wait_closed())
    log.debug('chiusura del ciclo di eventi')
    event_loop.close()
</py_code>
<titolo_3>
Client Che Riceve Quanto Inviato
</titolo_3>
<testo_normale>
La costruzione di un client è molto simile a quella di un server. Il codice inizia sempre con l'importazione dei moduli, quindi occorre impostare <code>asyncio</code> e <a href='logging.html' target='_blank'>logging</a>, quindi viene creato un oggetto per la gestione del ciclo di eventi
</testo_normale>
<py_code>
# asyncio_echo_client_protocol.py

import asyncio
import functools
import logging
import sys

MESSAGES = [
    b'Questo è il messaggio. ',
    b'Sarà inviato ',
    b'in parti.',
]
SERVER_ADDRESS = ('localhost', 10000)

logging.basicConfig(
    level=logging.DEBUG,
    format='%(name)s: %(message)s',
    stream=sys.stderr,
)
log = logging.getLogger('main')

event_loop = asyncio.get_event_loop()
</py_code>
<testo_normale>
La classe derivata da <code>asyncio.Protocol</code> definisce gli stessi metodi del server, con implementazioni differenti. Il costruttore della classe accetta due argomenti, una lista dei messaggi da inviare e una istanza di <code>Future</code> da usare per segnalare che il client ha completato un ciclo di lavoro in quanto ha ricevuto una risposta dal server.
</testo_normale>
<py_code>
class EchoClient(asyncio.Protocol):

    def __init__(self, messages, future):
        super().__init__()
        self.messages = messages
        self.log = logging.getLogger('EchoClient')
        self.f = future
</py_code>
<testo_normale>
Quando il client si connette con successo al server, inizia immediatamente la comunicazione. La sequenza dei messaggi viene inviata una alla vota, anche se il codice di rete sottostante possa combinare più messaggi in un'unica tramissione. Quando tutti i messaggi sono consumati, viene inviato un EOF.
</testo_normale>
<testo_normale>
Anche se sembra che tutti i dati siano stati inviati immediatamente, in effetti l'oggetto trasportatore parcheggia i dati in uscita e imposta un <a href='https://www.wikiwand.com/it/Callback' target='_blank'>callback</a> per inviare effettivamente i dati quando il <a href='https://www.wikiwand.com/it/Buffer' target='_blank'><em>buffer</em>r</a>  del <a href='https://www.wikiwand.com/it/Socket_(reti)' target='_blank'><em>socket</em>r</a>  è pronto a ricevere dati. Tutto questo è gestito in modo trasparente, quindi il codice dell'applicazione può essere scritto come se le operazioni di I/O avvenissero immediatamente.
</testo_normale>
<py_code>
    def connection_made(self, transport):
        self.transport = transport
        self.address = transport.get_extra_info('peername')
        self.log.debug(
            'connessione a {} porta {}'.format(*self.address)
        )
        # Potrebbe essere transport.writelines() eccetto che
        # avrebbe reso più difficile mestrare ciascuna parte del messaggio
        # che sta per essere spedito..
        for msg in self.messages:
            transport.write(msg)
            self.log.debug('in invio {!r}'.format(msg))
        if transport.can_write_eof():
            transport.write_eof()
</py_code>
<testo_normale>
Quando viene ricevuta la risposta dal server, viene registrata.
</testo_normale>
<py_code>
    def data_received(self, data):
        self.log.debug('ricevuto {!r}'.format(data))
</py_code>
<testo_normale>
Sia che venga ricevuto un marcatore di fine file (EOF) oppure che la connessione sia chiusa lato server, l'oggetto trasportatore locale vien chiuso e l'oggetto <code>Future</code> viene marcato come completato, impostandone il risultato
</testo_normale>
<py_code>
    def eof_received(self):
        self.log.debug('ricevuto EOF')
        self.transport.close()
        if not self.f.done():
            self.f.set_result(True)

    def connection_lost(self, exc):
        self.log.debug('il server ha chiuso la connessione')
        self.transport.close()
        if not self.f.done():
            self.f.set_result(True)
        super().connection_lost(exc)
</py_code>
<testo_normale>
Normalmente la classe derivata da <code>asyncio.Protocol</code> è passata al ciclo di eventi per creare la connessione. In questo caso, visto che il ciclo di eventi non ha un modo per passare argomenti supplementari al costruttore del protocollo, è necessario creare un <code>partial</code> per impacchettare la classe client e passare l'elenco dei messaggi da inviare e l'istanza di <code>Future</code>. Il nuovo chiamabile viene poi usato sul posto dalla classe quando si chiama <code>create_connection()</code> per stabilire la connessione client.
</testo_normale>
<py_code>
client_completed = asyncio.Future()

client_factory = functools.partial(
    EchoClient,
    messages=MESSAGES,
    future=client_completed,
)
factory_coroutine = event_loop.create_connection(
    client_factory,
    *SERVER_ADDRESS,
)
</py_code>
<testo_normale>
Per attivare l'esecuzione del client, il ciclo di eventi viene chiamato una volta con la <em>coroutine</em> per creare il cliente, quindi nuovamente con l'istanza di <code>Future</code> data al client per comunicare quando ha terminato. Usando due chiamate si evita l'avere un ciclo infinito nel programma client, che probabilmente vorrebbe terminare dopo che ha finito di comunicare con il server. Se fosse usata solo la prima chiamata per attendere la <em>coroutine</em> per creare il client, potrebbero non essere propriamente elaborati tutti i dati di risposta  e la pulizia della connessione al server.
</testo_normale>
<py_code>
log.debug('in attesa del client per completare')
try:
    event_loop.run_until_complete(factory_coroutine)
    event_loop.run_until_complete(client_completed)
finally:
    log.debug('chiusura del ciclo di eventi')
    event_loop.close()
</py_code>
<titolo_3>
Risultato
</titolo_3>
<testo_normale>
L'esecuzione del server in una finestra e del client in un'altra produce il seguente risultato
</testo_normale>
<py_output>
$ python3 asyncio_echo_client_protocol.py
asyncio: Using selector: EpollSelector
main: in attesa del client per completare
EchoClient: connessione a 127.0.0.1 porta 10000
EchoClient: in invio b"Questo e' il messaggio. "
EchoClient: in invio b"Sara' inviato "
EchoClient: in invio b'in parti.'
EchoClient: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
EchoClient: ricevuto EOF
EchoClient: il server ha chiuso la connessione
main: chiusura del ciclo di eventi

$ python3 asyncio_echo_client_protocol.py
asyncio: Using selector: EpollSelector
main: in attesa del client per completare
EchoClient: connessione a 127.0.0.1 porta 10000
EchoClient: in invio b"Questo e' il messaggio. "
EchoClient: in invio b"Sara' inviato "
EchoClient: in invio b'in parti.'
EchoClient: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
EchoClient: ricevuto EOF
EchoClient: il server ha chiuso la connessione
main: chiusura del ciclo di eventi

$ python3 asyncio_echo_client_protocol.py
asyncio: Using selector: EpollSelector
main: in attesa del client per completare
EchoClient: connessione a 127.0.0.1 porta 10000
EchoClient: in invio b"Questo e' il messaggio. "
EchoClient: in invio b"Sara' inviato "
EchoClient: in invio b'in parti.'
EchoClient: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
EchoClient: ricevuto EOF
EchoClient: il server ha chiuso la connessione
main: chiusura del ciclo di eventi
</py_output>
<testo_normale>
Anche se il client manda sempre i messaggi separatamente, la prima volta che il client viene eseguito, il server riceve un unico comprensivo messaggio e lo ritorna al client. Questi risultati variano in esecuzioni susseguenti, in base a quanto sia sovraccarica la rete e se i <a href='https://www.wikiwand.com/it/Buffer' target='_blank'><em>buffer</em>r</a> di rete siano svuotati prima che tutti i dati siano preparati.
</testo_normale>
<py_output>
python3.7 asyncio_echo_server_protocol.py
asyncio: Using selector: EpollSelector
main: in partenza on localhost porta 10000
EchoServer_127.0.0.1_46464: connessione accettata
EchoServer_127.0.0.1_46464: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
EchoServer_127.0.0.1_46464: inviato b"Questo e' il messaggio. Sara' inviato in parti."
EchoServer_127.0.0.1_46464: ricevuto EOF
EchoServer_127.0.0.1_46464: chiusura

EchoServer_127.0.0.1_46470: connessione accettata
EchoServer_127.0.0.1_46470: ricevuto b"Questo e' il messaggio. "
EchoServer_127.0.0.1_46470: inviato b"Questo e' il messaggio. "
EchoServer_127.0.0.1_46470: ricevuto b"Sara' inviato in parti."
EchoServer_127.0.0.1_46470: inviato b"Sara' inviato in parti."
EchoServer_127.0.0.1_46470: ricevuto EOF
EchoServer_127.0.0.1_46470: chiusura

EchoServer_127.0.0.1_46472: connessione accettata
EchoServer_127.0.0.1_46472: ricevuto b"Questo e' il messaggio. Sara' inviato "
EchoServer_127.0.0.1_46472: inviato b"Questo e' il messaggio. Sara' inviato "
EchoServer_127.0.0.1_46472: ricevuto b"in parti."
EchoServer_127.0.0.1_46472: inviato b"in parti."
EchoServer_127.0.0.1_46472: ricevuto EOF
EchoServer_127.0.0.1_46472: chiusura
</py_output>
<titolo_2>
I/O Asincrono Usando Coroutine e Canali
</titolo_2>
<testo_normale>
Questa sezione esamina versioni alternative dei due programmi di esempio qui sopra, usando <em>coroutine</em> e <a href='https://www.wikiwand.com/it/Application_programming_interface' target='_blank'>API</a> per i canali di <code>asyncio</code> in luogo delle astrazioni di classi per il protocollo e il trasporto. Questi esempi operano a un livello di astrazione inveriore rispetto all'<a href='https://www.wikiwand.com/it/Application_programming_interface' target='_blank'>API</a> <code>Protocol</code> discussa precedentemente, ma gli eventi elaborati sono simili.
</testo_normale>
<titolo_3>
Server Che Invia Quanto Ricevuto
</titolo_3>
<testo_normale>
Il server inizia importando i moduli e deve impostare <code>asyncio</code> e <a href='logging.html' target='_blank'>logging</a>, quindi crea l'oggetto per il ciclo di eventi.
</testo_normale>
<py_code>
# asyncio_echo_server_coroutine.py

import asyncio
import logging
import sys

SERVER_ADDRESS = ('localhost', 10000)
logging.basicConfig(
    level=logging.DEBUG,
    format='%(name)s: %(message)s',
    stream=sys.stderr,
)
log = logging.getLogger('main')

event_loop = asyncio.get_event_loop()
</py_code>
<testo_normale>
Quindi definisce una coroutine per gestire la comunicazione. Ogni volta che si connette un client, viene invocata una nuova istanza della coroutine in modo che all'interno della funzione il codice comunichi con un solo client alla volta. Il linguaggio in esecuzione di Python gesetisce lo stato per ciascuna istanza di coroutine, in modo che il codice dell'applicazione non deve gestire strutture dati supplementari per tracciare client separati.
</testo_normale>
<testo_normale>
Gli argomenti per le coroutine sono istanze di <code>StreamrReader</code> e <code>StreamWrite</code> associate con la nuova connessione. Così come per <code>Transport</code>, l'indirizzo del client può essere raggiunto attraverso il metodo <code>get_extra_info()</code>.
</testo_normale>
<py_code>
async def echo(reader, writer):
    address = writer.get_extra_info('peername')
    log = logging.getLogger('echo_{}_{}'.format(*address))
    log.debug('connessione accettata')
</py_code>
<testo_normale>
Sebbele la coroutine sia chiamata quando viene stabilita la connessione, potrebbero non esserci ancora dati da leggere. Per evitare di bloccare mentre si sta leggendo, la coroutine usa <code>await</code> con la chiamata di <code>read()</code> per consentire al ciclo di eventi di proseguire elaborando altri compiti fino a quando non ci sono dati da leggere.
</testo_normale>
<py_code>
    while True:
        data = await reader.read(128)
</py_code>
<testo_normale>
Se il client invia dati, sono ritornati da <code>await</code> e possono essere restituiti al client passandolo all'oggetto che li scrive. Chiamate multiple a <code>write()</code> possono essere usate per accumulare dati in uscita, per poi usare <code>drain()</code> per far uscire i dati. Visto che questa opearzione di I/O su rete può bloccare, ancora una volta viene usato <code>await</code> per riportare il controllo al ciclo di eventi, che monitora il <em>socket</em> di scrittura e chiama l'oggetto che scrive quando possibile per inviare ulteriori dati.
</testo_normale>
<py_code>
        if data:
            log.debug('ricevuto {!r}'.format(data))
            writer.write(data)
            await writer.drain()
            log.debug('inviato {!r}'.format(data))
</py_code>
<testo_normale>
Se il client non ha inviato dati, <code>read()</code> ritorna una stringa di byte vuota per indicare che la connessione è chiusa. Il server deve chiudere il socket per scrivere al client, poi la coroutine può ritornare per indicare che ha terminato.
</testo_normale>
<py_code>
        else:
            log.debug('in chiusura')
            writer.close()
            return
</py_code>
<testo_normale>
Ci sono due passi per far partire il server. Prima l'applicazione dice al ciclo di eventi di creare un nuovo oggetto server usando la coroutine, il nome host e il <em>socket</em> sul quale ascoltare. Il metodo <code>start_server()</code> è esso stesso una coroutine, quindi i risultati devono essere elaborati dal ciclo di eventi per far effettivamente partire il server. Il completamento della coroutine produce una istanza di <code>asyncio.Server</code> legata al ciclo di eventi
</testo_normale>
<py_code>
# Crea il server e lascia che ciclo termini la coroutine prima di far
# partire il ciclo di eventi effettivo.
factory = asyncio.start_server(echo, *SERVER_ADDRESS)
server = event_loop.run_until_complete(factory)
log.debug('in partenza su {} porta {}'.format(*SERVER_ADDRESS))
</py_code>
<testo_normale>
Successivamente il ciclo di eventi deve essere eseguito per elaborare eventi e gestire le richieste dei cleint. Per un servizio che sia attivo per lunghi periodi, il metodo <code>run_forever()</code> è il modo più semplice per farlo. Quando il ciclo di eventi viene fermato, sia dal codice dell'applicazione che da un segnale inviato al processo, il server puà essere chiuso per pulire correttamente il <em>socket</em>, quindi il ciclo di eventi puà essere chiuso per finire la gestione di ogni altra coroutine prima che il programma esca.
</testo_normale>
<py_code>
# Entra nel ciclo di eventi permanentemente per gestire tutte le connesisoni.
try:
    event_loop.run_forever()
except KeyboardInterrupt:
    pass
finally:
    log.debug('server in chiusura')
    server.close()
    event_loop.run_until_complete(server.wait_closed())
    log.debug('chiusura del ciclo di eventi')
    event_loop.close()
</py_code>
<titolo_3>
Client che Riceve Quanto Inviato
</titolo_3>
<testo_normale>
La costruzione di un client usando una <em>coroutine</em> è molto simile alla costruzione di un server. Ancora una volta il codice inizia importando i moduli necessari per impostare <code>asyncio</code> e <a href='logging.html' target='_blank'>logging</a>, quindi crea un oggetto per il ciclo di eventi
</testo_normale>
<py_code>
# asyncio_echo_client_coroutine.py

import asyncio
import logging
import sys

MESSAGES = [
    b"Questo e' il messaggio. ",
    b"Sara' inviato ",
    b'in parti.',
]
SERVER_ADDRESS = ('localhost', 10000)

logging.basicConfig(
    level=logging.DEBUG,
    format='%(name)s: %(message)s',
    stream=sys.stderr,
)
log = logging.getLogger('main')

event_loop = asyncio.get_event_loop()
</py_code>
<testo_normale>
La <em>coroutine</em> <code>echo_client</code> riceve argomenti che indicano dove sia il server e quale messaggi spedire
</testo_normale>
<py_code>
async def echo_client(address, messages):
</py_code>
<testo_normale>
La <em>coroutine</em> viene chiamata quando inizia l'attività, ma non ha connessioni attive con cui lavorare. Il primo passo, quindi, è quello di impostare al client la sua propria connessione. Usa <code>await</code> per evitare di bloccare altre attività mentre è in esecuzione la <em>coroutine</em> <code>open_connection()</code>.
</testo_normale>
<py_code>
    log = logging.getLogger('echo_client')

    log.debug('connessione a {} porta {}'.format(*address))
    reader, writer = await asyncio.open_connection(*address)
</py_code>
<testo_normale>
La <em>coroutine</em> <code>open_connection()</code> ritorna istanze di <code>StreamReader</code>  e <code>StreamWrite</code> associate con il nuovo socket. Il prossimo passo è usare l'oggetto di scrittura per inviare dati al server. Sul server, l'oggetto di scrittura accumulerà i dati in arrivo fino a che il socket è pronto oppure venga usato <code>drain()</code> per forzare la fuoriuscita. Visto questa azione di I/O sulla rete può bloccare, viene usato <code>async</code> ancora una volta per restituire il controllo al ciclo di eventi, il quale monitora il socket di scrittura e chiama l'oggetto che scrive quando possibile per inviare ulteriori dati.
</testo_normale>
<py_code>
    # Potrebbe essere writer.writelines() eccetto che
    # avrebbe reso più difficile mestrare ciascuna parte del messaggio
    # che sta per essere spedito..
    for msg in messages:
        writer.write(msg)
        log.debug('in invio {!r}'.format(msg))
    if writer.can_write_eof():
        writer.write_eof()
    await writer.drain()
</py_code>
<testo_normale>
Successivamente il client cerca una risposa dal server tentando di leggere i dati fino che quando non rimane più nulla da leggere. Per evitare il bloccaggio su ogni singola chiamata di <code>read()</code>, <code>await</code> restituisce il controllo al ciclo di eventi. Se il server ha inviato dati, vengono registrati. Se il server non ha inviato dati, <code>read()</code> ritorna una stringa di byte vuota per indicate che la connessione è chiusa. Il client deve chiudere il socket usato per inviare dati al server, quindi ritornare per indicare che ha terminato.
</testo_normale>
<py_code>
    log.debug('in attesa di risposta')
    while True:
        data = await reader.read(128)
        if data:
            log.debug('ricevuto {!r}'.format(data))
        else:
            log.debug('in chiusura')
            writer.close()
            return
</py_code>
<testo_normale>
Per far partire il client, il ciclo di eventi viene chiamato con la <em>coroutine</em> per la creazione del client. L'utilizzo di <code>run_until_complete()</code> evita di avere un ciclo infinito nel programma client. Al contrario dell'esempio sul protocollo visto in precedenza, non è necessario un <em>future</em> separato per segnalare quando la coroutine è finita, poichè <code>echo_client()</code> contiene esso stesso tutta la logica client e non ritorna fino a che ha ricevuto una risposta e chiuso la connessione al server.
</testo_normale>
<titolo_3>
Risultato
</titolo_3>
<testo_normale>
L'esecuzione del server in una finestra di terminale e del client in un'altra, produce il seguente risultato
</testo_normale>
<py_output>
$ python3 asyncio_echo_client_coroutine.py
asyncio: Using selector: EpollSelector
echo_client: connessione a localhost porta 10000
echo_client: in invio b"Questo e' il messaggio. "
echo_client: in invio b"Sara' inviato "
echo_client: in invio b'in parti.'
echo_client: in attesa di risposta
echo_client: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
echo_client: in chiusura
main: chiusura del ciclo di eventi

$ python3 asyncio_echo_client_coroutine.py
asyncio: Using selector: EpollSelector
echo_client: connessione a localhost porta 10000
echo_client: in invio b"Questo e' il messaggio. "
echo_client: in invio b"Sara' inviato "
echo_client: in invio b'in parti.'
echo_client: in attesa di risposta
echo_client: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
echo_client: in chiusura
main: chiusura del ciclo di eventi

$ python3 asyncio_echo_client_coroutine.py
asyncio: Using selector: EpollSelector
echo_client: connessione a localhost porta 10000
echo_client: in invio b"Questo e' il messaggio. "
echo_client: in invio b"Sara' inviato "
echo_client: in invio b'in parti.'
echo_client: in attesa di risposta
echo_client: ricevuto b"Questo e' il messaggio. Sara' inviato "
echo_client: ricevuto b"in parti."
echo_client: in chiusura
main: chiusura del ciclo di eventi
</py_output>
<testo_normale>
Sebbene il client invii sempre i messaggi separatamente, le prime due volta che il client viene eseguito il server riceve un messaggio più grande che ripete al client. Questi risultati variano nelle esecuzioni successive, in base a quanto impegnata sia la rete e se i buffer di rete vengano svuotati prima che tutti i dati siano preparati.
</testo_normale>
<py_output>
$ python3 asyncio_echo_server_coroutine.py

asyncio: Using selector: EpollSelector
main: in partenza su localhost porta 10000
echo_127.0.0.1_50818: connessione accettata
echo_127.0.0.1_50818: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
echo_127.0.0.1_50818: inviato b"Questo e' il messaggio. Sara' inviato in parti."
echo_127.0.0.1_50818: in chiusura
echo_127.0.0.1_50820: connessione accettata
echo_127.0.0.1_50820: ricevuto b"Questo e' il messaggio. Sara' inviato in parti."
echo_127.0.0.1_50820: inviato b"Questo e' il messaggio. Sara' inviato in parti."
echo_127.0.0.1_50820: in chiusura
echo_127.0.0.1_50822: connessione accettata
echo_127.0.0.1_50822: ricevuto b"Questo e' il messaggio. Sara' inviato"
echo_127.0.0.1_50822: inviato b"Questo e' il messaggio. Sara' inviato"
echo_127.0.0.1_50822: ricevuto b" in parti"
echo_127.0.0.1_50822: inviato b" in parti"
echo_127.0.0.1_50822: in chiusura
main: chiusura del ciclo di eventi
</py_output>
<titolo_2>
Usare SSL
</titolo_2>
<testo_normale>
<code>asyncio</code> ha incorporato il supporto per permetter di comunicazioni SSL sui socket. Il passaggio di una istanza di <code>SSLContext</code> alle <em>coroutine</em> che creano connessioni server o client abilita i supporto e fa sì che l'impostazione del protocollo SSL sia compiuta prima che il socket sia presentato come pronto all'utilizzo dall'applicazione
</testo_normale>
<testo_normale>
I server e client basati sulle <em>coroutine</em> della sezione precedente possono essere aggiornati con pochi piccoli cambiamenti. Il primo passo è la creazione del certificato e dei file chiave. Un certificato auto firmato può essere create con un comando tipo:
</testo_normale>
<py_output>
$ openssl req -newkey rsa:2048 -nodes -keyout pymotw.key \
-x509 -days 365 -out pymotw.crt
</py_output>
<testo_normale>
Il comando <code>openssl</code> richiederà all'utente diversi valor che verranno usati per generare il certificato, quindi produrrà i file in uscita richiesti.
</testo_normale>
<testo_normale>
L'impostazione non sicura del socket dell'esempio del server precedente usa <code>start_server()</code> per creare il socket in ascolto.
</testo_normale>
<py_code>
factory = asyncio.start_server(echo, *SERVER_ADDRESS)
server = event_loop.run_until_complete(factory)
</py_code>
<testo_normale>
Per aggiungere la codifica, si crei un oggetto <code>SSLContext</code> con il certificato e la chiave appena generati, quindi lo si passi a <code>start_server()</code>
</testo_normale>
<py_code>
# Il certificato è creato con pymotw.com come nome host,
# il che non corrisponderà quando il codice di esempio viene eseguito
# altrove, quindi si disabiliti la verifica del nome host
ssl_context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
ssl_context.check_hostname = False
ssl_context.load_cert_chain('pymotw.crt', 'pymotw.key')

# Crea il server e lascia che il ciclo finisca la coroutine prima di
# far partire il ciclo di eventi effettivo
factory = asyncio.start_server(echo, *SERVER_ADDRESS, ssl=ssl_context)
</py_code>
<testo_normale>
Simili modifiche sono necessarie nel client. La vecchia versione usa <code>open_connection()</code> per creare il socket connesso al server
</testo_normale>
<py_code>
reader, writer = await asyncio.open_connection(*address)
</py_code>
<testo_normale>
Anche qui è richiesto un <code>SSLContext</code> per mettere in sicurezza la parte client del socket. L'identità del client non viene forzata, quindi si deve caricare solo il certificato.
</testo_normale>
<py_code>
    # Il certificato è creato con pymotw.com come nome host,
    # il che non corrisponderà quando il codice di esempio viene eseguito
    # altrove, quindi si disabiliti la verifica del nome host
    ssl_context = ssl.create_default_context(
        ssl.Purpose.SERVER_AUTH,
    )
    ssl_context.check_hostname = False
    ssl_context.load_verify_locations('pymotw.crt')
    reader, writer = await asyncio.open_connection(
        *server_address, ssl=ssl_context)
</py_code>


<vedi_anche>
https://docs.python.org/3.5/library/multiprocessing.html|multiprocessing|La documentazione della libreria standard per questo modulo.
threading.html|threading|API di alto livello per lvaorare con i thread
https://it.wikipedia.org/wiki/MapReduce|MapReduce - Wikipedia|Panoramica di MapReduce su Wikipedia
http://research.google.com/archive/mapreduce.html|MapReduce: Simplified Dsta Processing on Large Clusters| Presentazione e documento su MapReduce da parte di Google Labs
operator.html|Operator|Strumenti sugli operatori tipo <code>itemgetter</code>
</vedi_anche>
</documento_tradotto>
